{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepared for Gabor's Data Analysis\n",
    "\n",
    "### Data Analysis for Business, Economics, and Policy\n",
    "by Gabor Bekes and  Gabor Kezdi\n",
    " \n",
    "Cambridge University Press 2021\n",
    "\n",
    "**[gabors-data-analysis.com ](https://gabors-data-analysis.com/)**\n",
    "\n",
    " License: Free to share, modify and use for educational purposes. \n",
    " Not to be used for commercial purposes.\n",
    "\n",
    "### CHAPTER 22\n",
    "**CH22A How does a merger between airlines affect prices?**\n",
    "\n",
    " using the airline-tickets-usa dataset\n",
    " \n",
    " version 1.0 2021-05-05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "from datetime import datetime as dt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.formula.api as smf\n",
    "from IPython.core.display import HTML\n",
    "from mizani.formatters import percent_format\n",
    "from mizani.formatters import date_format\n",
    "from plotnine import *\n",
    "from stargazer.stargazer import Stargazer\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Current script folder\n",
    "current_path = os.getcwd()\n",
    "dirname = current_path.split(\"da_case_studies\")[0]\n",
    "\n",
    "# location folders\n",
    "data_in = dirname + \"da_data_repo/airline-tickets-usa/clean/\"\n",
    "data_out = dirname + \"da_case_studies/ch22-airline-merger-prices/\"\n",
    "output = dirname + \"da_case_studies/ch22-airline-merger-prices/output/\"\n",
    "\n",
    "func = dirname + \"da_case_studies/ch00-tech-prep/\"\n",
    "sys.path.append(func)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the prewritten helper functions\n",
    "from py_helper_functions import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I.  Examining pre-treatment trends in avg ln price"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "workfile to identify treated and untreated markets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_work = pd.read_pickle(data_out + \"ch22-airline-workfile.pkl\").loc[\n",
    "    lambda x: (x[\"balanced\"] == 1) & (x[\"year\"] == 2011)\n",
    "][[\"origin\", \"finaldest\", \"return\", \"treated\", \"smallmkt\"]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "use year-quarter panel data and merge to it treated-untreated \n",
    "\n",
    "(keep matched ones; no unmatched from \"using\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_stata(data_in + \"originfinal-panel.dta\")\n",
    "data = pd.merge(data, data_work, on=[\"origin\", \"finaldest\", \"return\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "aggreagete data to create average price by treated-untreated and year-quarter and draw time series graphs of log avg price all markets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_avg = lambda x: np.average(x, weights=data.loc[x.index, \"passengers\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "DateParseError",
     "evalue": "Unknown datetime string format, unable to parse: 2010 Q2, at position 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDateParseError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 11\u001b[0m\n\u001b[1;32m      7\u001b[0m data_agg[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlnavgprice\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlog(data_agg[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mavgprice\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m      8\u001b[0m data_agg[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquarters\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m      9\u001b[0m     data_agg[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myear\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Q\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m data_agg[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquarter\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mstr\u001b[39m)\n\u001b[1;32m     10\u001b[0m )\n\u001b[0;32m---> 11\u001b[0m data_agg[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(\n\u001b[1;32m     12\u001b[0m     data_agg[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquarters\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms+\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     13\u001b[0m )\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39mto_period(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQ\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/myenv/lib/python3.12/site-packages/pandas/core/tools/datetimes.py:1067\u001b[0m, in \u001b[0;36mto_datetime\u001b[0;34m(arg, errors, dayfirst, yearfirst, utc, format, exact, unit, infer_datetime_format, origin, cache)\u001b[0m\n\u001b[1;32m   1065\u001b[0m         result \u001b[38;5;241m=\u001b[39m arg\u001b[38;5;241m.\u001b[39mmap(cache_array)\n\u001b[1;32m   1066\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1067\u001b[0m         values \u001b[38;5;241m=\u001b[39m convert_listlike(arg\u001b[38;5;241m.\u001b[39m_values, \u001b[38;5;28mformat\u001b[39m)\n\u001b[1;32m   1068\u001b[0m         result \u001b[38;5;241m=\u001b[39m arg\u001b[38;5;241m.\u001b[39m_constructor(values, index\u001b[38;5;241m=\u001b[39marg\u001b[38;5;241m.\u001b[39mindex, name\u001b[38;5;241m=\u001b[39marg\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m   1069\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arg, (ABCDataFrame, abc\u001b[38;5;241m.\u001b[39mMutableMapping)):\n",
      "File \u001b[0;32m/opt/anaconda3/envs/myenv/lib/python3.12/site-packages/pandas/core/tools/datetimes.py:435\u001b[0m, in \u001b[0;36m_convert_listlike_datetimes\u001b[0;34m(arg, format, name, utc, unit, errors, dayfirst, yearfirst, exact)\u001b[0m\n\u001b[1;32m    432\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmixed\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    433\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _array_strptime_with_fallback(arg, name, utc, \u001b[38;5;28mformat\u001b[39m, exact, errors)\n\u001b[0;32m--> 435\u001b[0m result, tz_parsed \u001b[38;5;241m=\u001b[39m objects_to_datetime64(\n\u001b[1;32m    436\u001b[0m     arg,\n\u001b[1;32m    437\u001b[0m     dayfirst\u001b[38;5;241m=\u001b[39mdayfirst,\n\u001b[1;32m    438\u001b[0m     yearfirst\u001b[38;5;241m=\u001b[39myearfirst,\n\u001b[1;32m    439\u001b[0m     utc\u001b[38;5;241m=\u001b[39mutc,\n\u001b[1;32m    440\u001b[0m     errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[1;32m    441\u001b[0m     allow_object\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    442\u001b[0m )\n\u001b[1;32m    444\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tz_parsed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    445\u001b[0m     \u001b[38;5;66;03m# We can take a shortcut since the datetime64 numpy array\u001b[39;00m\n\u001b[1;32m    446\u001b[0m     \u001b[38;5;66;03m# is in UTC\u001b[39;00m\n\u001b[1;32m    447\u001b[0m     out_unit \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdatetime_data(result\u001b[38;5;241m.\u001b[39mdtype)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m/opt/anaconda3/envs/myenv/lib/python3.12/site-packages/pandas/core/arrays/datetimes.py:2398\u001b[0m, in \u001b[0;36mobjects_to_datetime64\u001b[0;34m(data, dayfirst, yearfirst, utc, errors, allow_object, out_unit)\u001b[0m\n\u001b[1;32m   2395\u001b[0m \u001b[38;5;66;03m# if str-dtype, convert\u001b[39;00m\n\u001b[1;32m   2396\u001b[0m data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(data, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mobject_)\n\u001b[0;32m-> 2398\u001b[0m result, tz_parsed \u001b[38;5;241m=\u001b[39m tslib\u001b[38;5;241m.\u001b[39marray_to_datetime(\n\u001b[1;32m   2399\u001b[0m     data,\n\u001b[1;32m   2400\u001b[0m     errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[1;32m   2401\u001b[0m     utc\u001b[38;5;241m=\u001b[39mutc,\n\u001b[1;32m   2402\u001b[0m     dayfirst\u001b[38;5;241m=\u001b[39mdayfirst,\n\u001b[1;32m   2403\u001b[0m     yearfirst\u001b[38;5;241m=\u001b[39myearfirst,\n\u001b[1;32m   2404\u001b[0m     creso\u001b[38;5;241m=\u001b[39mabbrev_to_npy_unit(out_unit),\n\u001b[1;32m   2405\u001b[0m )\n\u001b[1;32m   2407\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tz_parsed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2408\u001b[0m     \u001b[38;5;66;03m# We can take a shortcut since the datetime64 numpy array\u001b[39;00m\n\u001b[1;32m   2409\u001b[0m     \u001b[38;5;66;03m#  is in UTC\u001b[39;00m\n\u001b[1;32m   2410\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result, tz_parsed\n",
      "File \u001b[0;32mtslib.pyx:414\u001b[0m, in \u001b[0;36mpandas._libs.tslib.array_to_datetime\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mtslib.pyx:596\u001b[0m, in \u001b[0;36mpandas._libs.tslib.array_to_datetime\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mtslib.pyx:553\u001b[0m, in \u001b[0;36mpandas._libs.tslib.array_to_datetime\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mconversion.pyx:641\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.conversion.convert_str_to_tsobject\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mparsing.pyx:336\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.parsing.parse_datetime_string\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mparsing.pyx:666\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.parsing.dateutil_parse\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mDateParseError\u001b[0m: Unknown datetime string format, unable to parse: 2010 Q2, at position 0"
     ]
    }
   ],
   "source": [
    "data_agg = (\n",
    "    data.groupby([\"treated\", \"year\", \"quarter\"])\n",
    "    .agg(avgprice=(\"avgprice\", weighted_avg))\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "data_agg[\"lnavgprice\"] = np.log(data_agg[\"avgprice\"])\n",
    "data_agg[\"quarters\"] = (\n",
    "    data_agg[\"year\"].astype(str) + \" Q\" + data_agg[\"quarter\"].astype(str)\n",
    ")\n",
    "data_agg[\"date\"] = pd.to_datetime(\n",
    "    data_agg[\"quarters\"].str.replace(\"\\s+\", \"\")\n",
    ").dt.to_period(\"Q\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    ggplot(data_agg, aes(x=\"date\", y=\"lnavgprice\", color=\"treated\", group=\"treated\"))\n",
    "    + geom_line(size=1.3)\n",
    "    + scale_color_manual(values=(color[0], color[1]), guide=False)\n",
    "    + scale_x_datetime(\n",
    "        limits=(\n",
    "            dt.strptime(\"2010-01-01\", \"%Y-%m-%d\"),\n",
    "            dt.strptime(\"2017-01-01\", \"%Y-%m-%d\"),\n",
    "        ),\n",
    "        breaks=[\"2010-01-01\", \"2012-01-01\", \"2014-01-01\", \"2016-01-01\"],\n",
    "        labels=date_format(\"%Y%Q\"),\n",
    "    )\n",
    "    + scale_y_continuous(expand=(0.01, 0.01), limits=(5, 5.6), breaks=seq(5, 5.6, 0.1))\n",
    "    + annotate(\n",
    "        \"text\",\n",
    "        x=data_agg.loc[data_agg[\"quarters\"] == \"2013 Q1\", \"date\"].values[0],\n",
    "        y=5.14,\n",
    "        label=\"Treated markets\",\n",
    "        size=10,\n",
    "        color=color[1],\n",
    "    )\n",
    "    + annotate(\n",
    "        \"text\",\n",
    "        x=data_agg.loc[data_agg[\"quarters\"] == \"2013 Q1\", \"date\"].values[0],\n",
    "        y=5.46,\n",
    "        label=\"Unreated markets\",\n",
    "        size=10,\n",
    "        color=color[0],\n",
    "    )\n",
    "    + geom_vline(\n",
    "        xintercept=data_agg.loc[data_agg[\"quarters\"] == \"2012 Q1\", \"date\"].values[0],\n",
    "        color=color[2],\n",
    "        size=0.9,\n",
    "        linetype=\"dashed\",\n",
    "    )\n",
    "    + geom_vline(\n",
    "        xintercept=data_agg.loc[data_agg[\"quarters\"] == \"2015 Q3\", \"date\"].values[0],\n",
    "        color=color[2],\n",
    "        size=0.9,\n",
    "        linetype=\"dashed\",\n",
    "    )\n",
    "    + annotate(\n",
    "        \"text\",\n",
    "        x=data_agg.loc[data_agg[\"quarters\"] == \"2011 Q1\", \"date\"].values[0],\n",
    "        y=5.57,\n",
    "        label=\"Announcement\",\n",
    "        size=7,\n",
    "        color=color[2],\n",
    "    )\n",
    "    + annotate(\n",
    "        \"text\",\n",
    "        x=data_agg.loc[data_agg[\"quarters\"] == \"2014 Q2\", \"date\"].values[0],\n",
    "        y=5.57,\n",
    "        label=\"Merger happens\",\n",
    "        size=7,\n",
    "        color=color[2],\n",
    "    )\n",
    "    + labs(y=\"ln(average price)\", x=\"\")\n",
    "    + theme_bw()\n",
    "    + theme(\n",
    "        axis_text_x=element_text(size=9),\n",
    "        axis_text_y=element_text(size=9),\n",
    "        axis_title_x=element_text(size=9),\n",
    "        axis_title_y=element_text(size=9),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Small markets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_agg = (\n",
    "    data.query(\"smallmkt == 1\")\n",
    "    .groupby([\"treated\", \"year\", \"quarter\"])\n",
    "    .agg(avgprice=(\"avgprice\", weighted_avg))\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "data_agg[\"lnavgprice\"] = np.log(data_agg[\"avgprice\"])\n",
    "data_agg[\"quarters\"] = (\n",
    "    data_agg[\"year\"].astype(str) + \" Q\" + data_agg[\"quarter\"].astype(str)\n",
    ")\n",
    "data_agg[\"date\"] = pd.to_datetime(\n",
    "    data_agg[\"quarters\"].str.replace(\"\\s+\", \"\")\n",
    ").dt.to_period(\"Q\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    ggplot(data_agg, aes(x=\"date\", y=\"lnavgprice\", color=\"treated\", group=\"treated\"))\n",
    "    + geom_line(size=1.3)\n",
    "    + scale_color_manual(values=(color[0], color[1]), guide=False)\n",
    "    + scale_x_datetime(\n",
    "        limits=(\n",
    "            dt.strptime(\"2010-01-01\", \"%Y-%m-%d\"),\n",
    "            dt.strptime(\"2017-01-01\", \"%Y-%m-%d\"),\n",
    "        ),\n",
    "        breaks=[\"2010-01-01\", \"2012-01-01\", \"2014-01-01\", \"2016-01-01\"],\n",
    "        labels=date_format(\"%Y%Q\"),\n",
    "    )\n",
    "    + scale_y_continuous(\n",
    "        expand=(0.01, 0.01), limits=(5.2, 5.7), breaks=seq(5.3, 5.6, 0.1)\n",
    "    )\n",
    "    + annotate(\n",
    "        \"text\",\n",
    "        x=data_agg.loc[data_agg[\"quarters\"] == \"2013 Q1\", \"date\"].values[0],\n",
    "        y=5.4,\n",
    "        label=\"Treated markets\",\n",
    "        size=9,\n",
    "        color=color[1],\n",
    "    )\n",
    "    + annotate(\n",
    "        \"text\",\n",
    "        x=data_agg.loc[data_agg[\"quarters\"] == \"2013 Q1\", \"date\"].values[0],\n",
    "        y=5.6,\n",
    "        label=\"Unreated markets\",\n",
    "        size=9,\n",
    "        color=color[0],\n",
    "    )\n",
    "    + geom_vline(\n",
    "        xintercept=data_agg.loc[data_agg[\"quarters\"] == \"2012 Q1\", \"date\"].values[0],\n",
    "        color=color[2],\n",
    "        size=0.9,\n",
    "        linetype=\"dashed\",\n",
    "    )\n",
    "    + geom_vline(\n",
    "        xintercept=data_agg.loc[data_agg[\"quarters\"] == \"2015 Q3\", \"date\"].values[0],\n",
    "        color=color[2],\n",
    "        size=0.9,\n",
    "        linetype=\"dashed\",\n",
    "    )\n",
    "    + labs(y=\"ln(average price)\", x=\"\")\n",
    "    + theme_bw()\n",
    "    + theme(\n",
    "        axis_text_x=element_text(size=9),\n",
    "        axis_text_y=element_text(size=9),\n",
    "        axis_title_x=element_text(size=9),\n",
    "        axis_title_y=element_text(size=9),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Large markets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_agg = (\n",
    "    data.query(\"smallmkt == 0\")\n",
    "    .groupby([\"treated\", \"year\", \"quarter\"])\n",
    "    .agg(avgprice=(\"avgprice\", weighted_avg))\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "data_agg[\"lnavgprice\"] = np.log(data_agg[\"avgprice\"])\n",
    "data_agg[\"quarters\"] = (\n",
    "    data_agg[\"year\"].astype(str) + \" Q\" + data_agg[\"quarter\"].astype(str)\n",
    ")\n",
    "data_agg[\"date\"] = pd.to_datetime(\n",
    "    data_agg[\"quarters\"].str.replace(\"\\s+\", \"\")\n",
    ").dt.to_period(\"Q\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    ggplot(data_agg, aes(x=\"date\", y=\"lnavgprice\", color=\"treated\", group=\"treated\"))\n",
    "    + geom_line(size=1.3)\n",
    "    + scale_color_manual(values=(color[0], color[1]), guide=False)\n",
    "    + scale_x_datetime(\n",
    "        limits=(\n",
    "            dt.strptime(\"2010-01-01\", \"%Y-%m-%d\"),\n",
    "            dt.strptime(\"2017-01-01\", \"%Y-%m-%d\"),\n",
    "        ),\n",
    "        breaks=[\"2010-01-01\", \"2012-01-01\", \"2014-01-01\", \"2016-01-01\"],\n",
    "        labels=date_format(\"%Y%Q\"),\n",
    "    )\n",
    "    + scale_y_continuous(\n",
    "        expand=(0.01, 0.01), limits=(3.75, 5), breaks=seq(3.75, 5, 0.25)\n",
    "    )\n",
    "    + annotate(\n",
    "        \"text\",\n",
    "        x=data_agg.loc[data_agg[\"quarters\"] == \"2013 Q1\", \"date\"].values[0],\n",
    "        y=4.7,\n",
    "        label=\"Treated markets\",\n",
    "        size=9,\n",
    "        color=color[1],\n",
    "    )\n",
    "    + annotate(\n",
    "        \"text\",\n",
    "        x=data_agg.loc[data_agg[\"quarters\"] == \"2013 Q1\", \"date\"].values[0],\n",
    "        y=4.3,\n",
    "        label=\"Unreated markets\",\n",
    "        size=9,\n",
    "        color=color[0],\n",
    "    )\n",
    "    + geom_vline(\n",
    "        xintercept=data_agg.loc[data_agg[\"quarters\"] == \"2012 Q1\", \"date\"].values[0],\n",
    "        color=color[2],\n",
    "        size=0.9,\n",
    "        linetype=\"dashed\",\n",
    "    )\n",
    "    + geom_vline(\n",
    "        xintercept=data_agg.loc[data_agg[\"quarters\"] == \"2015 Q3\", \"date\"].values[0],\n",
    "        color=color[2],\n",
    "        size=0.9,\n",
    "        linetype=\"dashed\",\n",
    "    )\n",
    "    + labs(y=\"ln(average price)\", x=\"\")\n",
    "    + theme_bw()\n",
    "    + theme(\n",
    "        axis_text_x=element_text(size=9),\n",
    "        axis_text_y=element_text(size=9),\n",
    "        axis_title_x=element_text(size=9),\n",
    "        axis_title_y=element_text(size=9),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II. ANALYSIS\n",
    "**Basic diff-in-diffs regression, weighted by # passengers on market, in before period**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload main file\n",
    "data_agg = pd.read_pickle(data_out + \"ch22-airline-workfile.pkl\")\n",
    "# keep balanced\n",
    "data_balanced = data_agg.query(\"balanced == 1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fd = smf.wls(\n",
    "    \"d_lnavgp ~ treated\", data_balanced, weights=data_balanced[\"pass_bef\"]\n",
    ").fit(cov_type=\"HC0\")\n",
    "fd_small = smf.wls(\n",
    "    \"d_lnavgp ~ treated\",\n",
    "    data_balanced.query(\"smallmkt == 1\"),\n",
    "    weights=data_balanced.query(\"smallmkt == 1\")[\"pass_bef\"],\n",
    ").fit(cov_type=\"HC0\")\n",
    "fd_large = smf.wls(\n",
    "    \"d_lnavgp ~ treated\",\n",
    "    data_balanced.query(\"smallmkt == 0\"),\n",
    "    weights=data_balanced.query(\"smallmkt == 0\")[\"pass_bef\"],\n",
    ").fit(cov_type=\"HC0\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stargazer = Stargazer([fd, fd_small, fd_large])\n",
    "stargazer.rename_covariates({\"Intercept\": \"Constant\"})\n",
    "stargazer.custom_columns([\"All markest\", \"Small markets\", \"Large markets\"], [1, 1, 1])\n",
    "HTML(stargazer.render_html())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Corresponding diff-in-diffs table\n",
    "weighted_avg = lambda x: np.average(\n",
    "    x,\n",
    "    weights=data_balanced.loc[data_balanced[\"lnavgp\"].notnull()].loc[\n",
    "        x.index, \"pass_bef\"\n",
    "    ],\n",
    ")\n",
    "data_balanced.loc[data_balanced[\"lnavgp\"].notnull()].groupby([\"after\", \"treated\"]).agg(\n",
    "    avgprice=(\"lnavgp\", weighted_avg), n=(\"lnavgp\", \"count\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Diff-in-diffs regression with confounder variables weighted by # passengers on market, in before period**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_balanced = data_balanced.merge(\n",
    "    data_balanced.loc[lambda x: x[\"before\"] == 1]\n",
    "    .assign(\n",
    "        lnpass=lambda x: np.log(x[\"passengers\"]),\n",
    "        sum_shares_bef=lambda x: x[\"shareAA\"] + x[\"shareUS\"],\n",
    "    )\n",
    "    .groupby(\"market\")\n",
    "    .agg(\n",
    "        lnpass_bef=(\"lnpass\", np.nanmean),\n",
    "        share_bef=(\"sum_shares_bef\", np.nanmean),\n",
    "        sharelarge_bef=(\"sharelargest\", np.nanmean),\n",
    "    )\n",
    "    .reset_index(),\n",
    "    on=\"market\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_balanced = data_balanced.rename(columns={\"return\": \"return_\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formula2 = \"d_lnavgp ~ treated + lnpass_bef + return_ + stops + sharelarge_bef\"\n",
    "\n",
    "fd2 = smf.wls(formula2, data_balanced, weights=data_balanced[\"pass_bef\"]).fit(\n",
    "    cov_type=\"HC1\"\n",
    ")\n",
    "fd2_small = smf.wls(\n",
    "    formula2,\n",
    "    data_balanced.query(\"smallmkt == 1\"),\n",
    "    weights=data_balanced.query(\"smallmkt == 1\")[\"pass_bef\"],\n",
    ").fit(cov_type=\"HC0\")\n",
    "fd2_large = smf.wls(\n",
    "    formula2,\n",
    "    data_balanced.query(\"smallmkt == 0\"),\n",
    "    weights=data_balanced.query(\"smallmkt == 0\")[\"pass_bef\"],\n",
    ").fit(cov_type=\"HC0\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stargazer = Stargazer([fd2, fd2_small, fd2_large])\n",
    "stargazer.rename_covariates({\"Intercept\": \"Constant\"})\n",
    "stargazer.custom_columns([\"All markest\", \"Small markets\", \"Large markets\"], [1, 1, 1])\n",
    "HTML(stargazer.render_html())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Diff-in-diffs regerssion with quantitative treatment weighted by # passengers on market, in before period**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "share_bef_1 = np.where(data_balanced.query(\"before == 1\")[\"share_bef\"] == 1, 1, 0)\n",
    "share_bef_0 = np.where(data_balanced.query(\"before == 1\")[\"share_bef\"] == 0, 1, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_balanced.query(\"before == 1\").groupby([share_bef_0, share_bef_1]).agg(\n",
    "    sum=(\"passengers\", sum), mean=(\"passengers\", \"mean\"), n=(\"passengers\", \"count\")\n",
    ")  # bit different from R\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    ggplot(\n",
    "        data_balanced, aes(x=\"share_bef\", y=\"stat(width*density)\", weight=\"pass_bef\")\n",
    "    )\n",
    "    + geom_histogram(\n",
    "        binwidth=0.05,\n",
    "        boundary=0,\n",
    "        fill=color[0],\n",
    "        alpha=0.8,\n",
    "        colour=\"white\",\n",
    "        size=1,\n",
    "        show_legend=False,\n",
    "    )\n",
    "    + labs(x=\"Market share of AA and US combined, at baseline\", y=\"Percent\")\n",
    "    + scale_x_continuous(\n",
    "        expand=(0.01, 0.01), limits=(0, 1), breaks=seq(0, 1, 0.25)\n",
    "    )\n",
    "    + scale_y_continuous(\n",
    "        expand=(0.0, 0.0),\n",
    "        limits=(0, 0.5),\n",
    "        breaks=seq(0, 0.5, 0.1),\n",
    "        labels=percent_format(),\n",
    "    )\n",
    "    + theme_bw()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formula3 = \"d_lnavgp ~ share_bef + lnpass_bef + return_ + stops + sharelarge_bef\"\n",
    "fd3 = smf.wls(formula3, data_balanced, weights=data_balanced[\"pass_bef\"]).fit(\n",
    "    cov_type=\"HC0\"\n",
    ")\n",
    "fd3_small = smf.wls(\n",
    "    formula3,\n",
    "    data_balanced.query(\"smallmkt == 1\"),\n",
    "    weights=data_balanced.query(\"smallmkt == 1\")[\"pass_bef\"],\n",
    ").fit(cov_type=\"HC0\")\n",
    "fd3_large = smf.wls(\n",
    "    formula3,\n",
    "    data_balanced.query(\"smallmkt == 0\"),\n",
    "    weights=data_balanced.query(\"smallmkt == 0\")[\"pass_bef\"],\n",
    ").fit(cov_type=\"HC0\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stargazer = Stargazer([fd3, fd3_small, fd3_large])\n",
    "stargazer.rename_covariates({\"Intercept\": \"Constant\"})\n",
    "stargazer.custom_columns([\"All markest\", \"Small markets\", \"Large markets\"], [1, 1, 1])\n",
    "HTML(stargazer.render_html())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Diff-in-diffs on pooled cross-sections regeression**\n",
    "* use entire unbalanced panel\n",
    "* errr... after only is dropped here see later\n",
    "* weighted by # passengers on market, in before period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_agg = data_agg.merge(\n",
    "    data_agg.loc[lambda x: x[\"before\"] == 1]\n",
    "    .assign(lnpass_bef=lambda x: np.log(x[\"passengers\"]))\n",
    "    .groupby(\"market\")\n",
    "    .agg(\n",
    "        lnpass_bef=(\"lnpass_bef\", np.nanmean),\n",
    "        sharelarge_bef=(\"sharelargest\", np.nanmean),\n",
    "    )\n",
    "    .reset_index(),\n",
    "    on=\"market\",\n",
    "    how=\"left\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_agg.groupby([\"balanced\", \"before\"]).agg({\"passengers\": [\"sum\", \"count\"]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# treatment group defined if observed before only or both before and after\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_agg = data_agg.merge(\n",
    "    data_agg.loc[lambda x: x[\"before\"] == 1]\n",
    "    .groupby(\"market\")\n",
    "    .agg(treatment=(\"AA_and_US\", np.nanmean))\n",
    "    .reset_index(),\n",
    "    on=\"market\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_agg[\"treatment_isna\"] = data_agg[\"treatment\"].isna()\n",
    "data_agg.groupby([\"treatment_isna\", \"balanced\"]).agg({\"passengers\": [\"sum\", \"count\"]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_agg = data_agg.rename(columns={\"return\": \"return_\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conditioning on observed confounders\n",
    "formula4 = \"lnavgp ~ (treatment + lnpass_bef + return_ + stops + sharelarge_bef)*after\"\n",
    "\n",
    "fd4 = smf.wls(formula4, data_agg, weights=data_agg[\"pass_bef\"]).fit(cov_type=\"HC0\")\n",
    "fd4_small = smf.wls(\n",
    "    formula4,\n",
    "    data_agg.query(\"smallmkt == 1\"),\n",
    "    weights=data_agg.query(\"smallmkt == 1\")[\"pass_bef\"],\n",
    ").fit(cov_type=\"HC0\")\n",
    "fd4_large = smf.wls(\n",
    "    formula4,\n",
    "    data_agg.query(\"smallmkt == 0\"),\n",
    "    weights=data_agg.query(\"smallmkt == 0\")[\"pass_bef\"],\n",
    ").fit(cov_type=\"HC0\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stargazer = Stargazer([fd4, fd4_small, fd4_large])\n",
    "stargazer.rename_covariates({\"Intercept\": \"Constant\"})\n",
    "stargazer.custom_columns([\"All markest\", \"Small markets\", \"Large markets\"], [1, 1, 1])\n",
    "HTML(stargazer.render_html())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "c01754e8627d0ea60fdf9a984fbf743943cf4db47884120dd04bfc512143b077"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
